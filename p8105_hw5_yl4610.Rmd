---
title: "p8105_hw5_yl4610"
output: github_document
date: "2022-11-08"
---

```{r setup, message=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)
```

# problem 1 

The code chunk below imports the data in individual spreadsheets contained in `./data/Q1data/`. To do this, I create a dataframe that includes the list of all files in that directory and the complete path to each file. As a next step, I `map` over paths and import data using the `read_csv` function. Finally, I `unnest` the result of `map`.

```{r, message=FALSE, warning=FALSE}
full_df = 
  tibble(
    files = list.files("data/Q1data/"),
    path = str_c("data/Q1data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```



# problem 2 
```{r, message=FALSE}
homicide_raw = read_csv( "./data/homicide_data.csv") 
```
This dataset contains variables such as `r names(homicide_raw)`. It contains `r ncol(homicide_raw)` columns and `r nrow(homicide_raw)` rows. 

```{r}
homicide = 
homicide_raw %>% 
  mutate (
    city_state = str_c(city, ", ", state),
    city_state = ifelse(city_state == "Tulsa, AL", "Tulsa, OK", city_state)) %>%
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition !="Closed by arrest"))

homicide
```

I used mutate to create a city_state variable. Then I used group_by and summarize to summarize within cities to obtain the total number of homicides and the number of unsolved homicides.

```{r}
baltimore = 
  homicide %>% 
  filter(city_state == "Baltimore, MD") 

prop.test(
  baltimore$unsolved_homicides,baltimore$total_homicides) %>% 
  broom::tidy()
```
I used filter to filter out other city_state except "Baltimore, MD". Then I used prop.test function to estimate the proportion of homicides that are unsolved and applied the broom::tidy to pull the estimated proportion and confidence intervals.

```{r}
city_final = 
  homicide %>% 
  mutate(
    outputs_df = map2 (unsolved_homicides,total_homicides, prop.test),
    final_outputs_df = map(outputs_df, broom::tidy)) %>% 
  unnest(final_outputs_df) %>% 
  select (city_state, estimate, conf.low, conf.high)

city_final
```
I used mutate to run prop.test for each of the cities and extract both the proportion of unsolved homicides and the confidence interval for each via purrr::map and purrr::map2. Then I unnested the final_outputs_df and selected variables I wanted to create a tidy dataframe with estimated proportions and CIs for each city.

```{r}
city_plot = 
city_final %>% 
ggplot(aes(x=fct_reorder(city_state, estimate), y=estimate))+
  geom_point()+
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high))+
  labs(
    title = "Estimates and confidence intervals of unsolved homocide for each city",
    x = "cities") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

city_plot
```
I used ggplot to create a scatter plot showing the estimates and CIs for each city. I used geom_errorbar to add error bars based on the upper and lower limits. I used fct_reorder to organize cities according to the proportion of unsolved homicides. lastly, I used labs to add title and x-axis label. 

# problem 3
```{r}
norm_dis = function(n = 30, mu, sigma = 5) {
  norm_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)) 
  
    norm_data %>% 
    t.test (mu = 0, alpha = 0.05, conf.level = 0.95) %>% 
      broom::tidy ()
}
norm_dis
```

```{r}
norm_results_df = 
  expand_grid(
    mu = 0:6,
    iter = 1:10) %>% 
  mutate(
    estimate_df = map(mu, ~norm_dis(mu=.x))
  ) %>% 
  unnest(estimate_df) 

norm_results_df
```
I conducted a simulation in a one-sample t-test with n=30, mu=0,1,2,3,4,5,6, and sd=5 via function. I generated 5000 datasets. 
# change ite size to 5000 at the end 

```{r}
plot_prop1 = 
norm_results_df %>%
  group_by(mu) %>%
  summarize(
    sum_pvalue = sum(p.value < 0.05),
    sum_n = n()) %>% 
  mutate (y_value = sum_pvalue/sum_n) %>% 
  ggplot(aes(x = mu, y = y_value)) + 
  geom_point() + 
  labs(title = "Proportion of times the null was rejected vs True means", 
       x = "True means",
       y = "Proportion of times the null was rejected") 

plot_prop1
```
I used ggplot to create a scatter plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of Î¼ on the x axis. 
As true mean increases, proportion of times the null was rejected increases. 
# effect sizes? correct calculation?

```{r}
plot_prop2 = 
norm_results_df %>%
  group_by(mu) %>%
  summarize(ave_estimate_mu = mean(estimate)) %>%
  ggplot(aes(x = mu, y = ave_estimate_mu, group = mu)) + 
  geom_point() + 
  labs(title = "Average estimate of mu hat vs True value of mu", 
       x = "True value of mu", 
       y = "Average estimate of mu hat") 
plot_prop2
```
I used ggplot to make a plot showing the average estimate of mu hat on the y axis and the true value of mu on the x axis. 

```{r}
plot_prop3 = 
norm_results_df %>%
  group_by(mu) %>%
  filter(p.value < 0.05) %>% 
  summarize(ave_estimate_mu = mean(estimate)) %>%
  ggplot(aes(x = mu, y = ave_estimate_mu, group = mu)) + 
  geom_point() + 
  labs(title = "Average estimate of mu hat vs True value of mu", 
       x = "True value of mu", 
       y = "Average estimate of mu hat only in samples for which the null was rejected") 
plot_prop3
```

I used ggplot to make a second plot showing the average estimate of mu hat only in samples for which the null was rejected on the y axis and the true value of mu on the x axis. 

The sample average of mu hat across tests for which the null is rejected is  approximately equal to the true value of mu when mu equals to 5 and 6 because as power and effect sizes increase, XXX







